{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral Normalization with MNIST (or Fashion MNIST)\n",
    "\n",
    "* `Spectral Normalization for Generative Adversarial Networks`, [arXiv:1802.05957](https://arxiv.org/abs/1802.05957)\n",
    "  * Takeru Miyato, Toshiki Kataoka, Masanori Koyama, Yuichi Yoshida\n",
    "  \n",
    "* This code is available to tensorflow version 2.0\n",
    "* Implemented by [`tf.keras.layers`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers) [`tf.losses`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/losses)\n",
    "* Use `transposed_conv2d` and `conv2d` for Generator and Discriminator, respectively.\n",
    "  * I do not use `dense` layer for model architecture consistency. (So my architecture is different from original dcgan structure)\n",
    "  \n",
    "* This code refers to [TensorFlow official tutorial dcgan code](https://www.tensorflow.org/alpha/tutorials/generative/dcgan)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import PIL\n",
    "import imageio\n",
    "from IPython import display\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setting hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Flags (hyperparameter configuration)\n",
    "model_name = 'spectral_norm'\n",
    "train_dir = os.path.join('train', model_name, 'exp1')\n",
    "dataset_name = 'mnist'\n",
    "assert dataset_name in ['mnist', 'fashion_mnist']\n",
    "\n",
    "max_epochs = 100\n",
    "save_model_epochs = 10\n",
    "print_steps = 200\n",
    "save_images_epochs = 1\n",
    "batch_size = 64\n",
    "learning_rate_D = 2e-4\n",
    "learning_rate_G = 2e-4\n",
    "k = 5 # the number of step of learning D before learning G (Not used in this code)\n",
    "num_examples_to_generate = 25\n",
    "noise_dim = 100\n",
    "MNIST_SIZE = 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and eval data from tf.keras\n",
    "if dataset_name == 'mnist':\n",
    "  (train_images, train_labels), _ = \\\n",
    "      tf.keras.datasets.mnist.load_data()\n",
    "else:\n",
    "  (train_images, train_labels), _ = \\\n",
    "      tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape(-1, MNIST_SIZE, MNIST_SIZE, 1).astype('float32')\n",
    "#train_images = train_images / 255. # Normalize the images to [0, 1]\n",
    "train_images = (train_images - 127.5) / 127.5 # Normalize the images to [-1, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Set up dataset with `tf.data`\n",
    "\n",
    "### create input pipeline with `tf.data.Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: (64, 28, 28, 1), types: tf.float32>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 20:55:20.538325: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-23 20:55:21.037518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 18516 MB memory:  -> device: 0, name: GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "#tf.random.set_seed(219)\n",
    "# for train\n",
    "N = len(train_images)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=N)\n",
    "train_dataset = train_dataset.batch(batch_size=batch_size, drop_remainder=True)\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create the generator and discriminator models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvTranspose(tf.keras.Model):\n",
    "  def __init__(self, filters, kernel_size, padding='same',\n",
    "               apply_batchnorm=True, activation='relu'):\n",
    "    super(ConvTranspose, self).__init__()\n",
    "    self.apply_batchnorm = apply_batchnorm\n",
    "    assert activation in ['relu', 'sigmoid', 'tanh']\n",
    "    self.activation = activation\n",
    "    self.up_conv = layers.Conv2DTranspose(filters=filters,\n",
    "                                          kernel_size=(kernel_size, kernel_size),\n",
    "                                          strides=2,\n",
    "                                          padding=padding,\n",
    "                                          kernel_initializer=tf.random_normal_initializer(0., 0.02),\n",
    "                                          use_bias=not self.apply_batchnorm)\n",
    "    if self.apply_batchnorm:\n",
    "      self.batchnorm = layers.BatchNormalization()\n",
    "\n",
    "  def call(self, x, training=True):\n",
    "    # conv transpose\n",
    "    x = self.up_conv(x)\n",
    "    \n",
    "    # batchnorm\n",
    "    if self.apply_batchnorm:\n",
    "      x = self.batchnorm(x, training=training)\n",
    "      \n",
    "    # activation\n",
    "    if self.activation == 'relu':\n",
    "      x = tf.nn.relu(x)\n",
    "    elif self.activation == 'sigmoid':\n",
    "      x = tf.nn.sigmoid(x)\n",
    "    else:\n",
    "      x = tf.nn.tanh(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(tf.keras.Model):\n",
    "  \"\"\"Build a generator that maps latent space to real space.\n",
    "    G(z): z -> x\n",
    "  \"\"\"\n",
    "  def __init__(self):\n",
    "    super(Generator, self).__init__()\n",
    "    self.conv1 = ConvTranspose(256, 3, padding='valid')\n",
    "    self.conv2 = ConvTranspose(128, 3, padding='valid')\n",
    "    self.conv3 = ConvTranspose(64, 4)\n",
    "    self.conv4 = ConvTranspose(1, 4, apply_batchnorm=False, activation='tanh')\n",
    "\n",
    "  def call(self, inputs, training=True):\n",
    "    \"\"\"Run the model.\"\"\"\n",
    "    # inputs: [1, 1, 100]\n",
    "    conv1 = self.conv1(inputs, training=training)           # conv1: [3, 3, 256]\n",
    "    conv2 = self.conv2(conv1, training=training)            # conv2: [7, 7, 128]\n",
    "    conv3 = self.conv3(conv2, training=training)            # conv3: [14, 14, 64]\n",
    "    generated_images = self.conv4(conv3, training=training) # generated_images: [28, 28, 1]\n",
    "    \n",
    "    return generated_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv(tf.keras.Model):\n",
    "  def __init__(self, filters, kernel_size, strides, padding='same',\n",
    "               apply_batchnorm=True, activation='relu', kernel_constraint=None):\n",
    "    super(Conv, self).__init__()\n",
    "    self.apply_batchnorm = apply_batchnorm\n",
    "    assert activation in ['relu', 'leaky_relu', 'none']\n",
    "    self.activation = activation\n",
    "        \n",
    "    self.conv = layers.Conv2D(filters=filters,\n",
    "                              kernel_size=(kernel_size, kernel_size),\n",
    "                              strides=strides,\n",
    "                              padding=padding,\n",
    "                              kernel_initializer=tf.random_normal_initializer(0., 0.02),\n",
    "                              use_bias=not self.apply_batchnorm,\n",
    "                              kernel_constraint=kernel_constraint)\n",
    "    if self.apply_batchnorm:\n",
    "      self.batchnorm = layers.BatchNormalization()\n",
    "  \n",
    "  def call(self, x, training=True):\n",
    "    # convolution\n",
    "    x = self.conv(x)\n",
    "    \n",
    "    # batchnorm\n",
    "    if self.apply_batchnorm:\n",
    "      x = self.batchnorm(x, training=training)\n",
    "    \n",
    "    # activation\n",
    "    if self.activation == 'relu':\n",
    "      x = tf.nn.relu(x)\n",
    "    elif self.activation == 'leaky_relu':\n",
    "      x = tf.nn.leaky_relu(x)\n",
    "    else:\n",
    "      pass\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralNorm(tf.keras.constraints.Constraint):\n",
    "    def __init__(self, iteration=1):\n",
    "        self.iteration = iteration\n",
    "    \n",
    "    def __call__(self, w):\n",
    "        \n",
    "        w_reshaped = tf.reshape(w, [-1, w.shape[-1]])\n",
    "        u_hat = tf.random.normal([1, w.shape[-1]])\n",
    "        \n",
    "        for _ in range(self.iteration):\n",
    "            v_ = u_hat @ tf.transpose(w_reshaped)\n",
    "            v_hat = tf.nn.l2_normalize(v_)\n",
    "            \n",
    "            u_ = v_hat @ w_reshaped\n",
    "            u_hat = tf.nn.l2_normalize(u_)\n",
    "        \n",
    "        sigma = v_hat @ w_reshaped @ tf.transpose(u_hat)\n",
    "        w_norm = w / sigma\n",
    "        \n",
    "        return w_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(tf.keras.Model):\n",
    "  \"\"\"Build a discriminator that discriminate real image x whether real or fake.\n",
    "    D(x): x -> [0, 1]\n",
    "  \"\"\"\n",
    "  def __init__(self):\n",
    "    super(Discriminator, self).__init__()\n",
    "    self.conv1 = Conv(64, 4, 2, apply_batchnorm=False, activation='leaky_relu', kernel_constraint=SpectralNorm())\n",
    "    self.conv2 = Conv(128, 4, 2, apply_batchnorm=False, activation='leaky_relu', kernel_constraint=SpectralNorm())\n",
    "    self.conv3 = Conv(256, 3, 2, padding='valid', apply_batchnorm=False, activation='leaky_relu', kernel_constraint=SpectralNorm())\n",
    "    self.conv4 = Conv(1, 3, 1, padding='valid', apply_batchnorm=False, activation='none', kernel_constraint=SpectralNorm())\n",
    "\n",
    "  def call(self, inputs, training=True):\n",
    "    \"\"\"Run the model.\"\"\"\n",
    "    # inputs: [28, 28, 1]\n",
    "    conv1 = self.conv1(inputs)                            # conv1: [14, 14, 64]\n",
    "    conv2 = self.conv2(conv1)                             # conv2: [7, 7, 128]\n",
    "    conv3 = self.conv3(conv2)                             # conv3: [3, 3, 256]\n",
    "    conv4 = self.conv4(conv3)                             # conv4: [1, 1, 1]\n",
    "    discriminator_logits = tf.squeeze(conv4, axis=[1, 2]) # discriminator_logits: [1,]\n",
    "    \n",
    "    return discriminator_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "discriminator = Discriminator()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot generated image via generator network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 20:56:44.909620: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2021-12-23 20:56:45.651634: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f726e0730d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "noise = tf.random.normal([1, 1, 1, noise_dim])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test discriminator network\n",
    "\n",
    "* **CAUTION**: the outputs of discriminator is **logits** (unnormalized probability) NOT probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-3.9943487e-05]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "decision = discriminator(generated_image)\n",
    "print(decision)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Define the loss functions and the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use logits for consistency with previous code I made\n",
    "# `tf.losses` and `tf.keras.losses` are the same API (alias)\n",
    "bce = tf.losses.BinaryCrossentropy(from_logits=True)\n",
    "mse = tf.losses.MeanSquaredError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WGANLoss(logits, is_real=True):\n",
    "  \"\"\"Computes Wasserstain GAN loss\n",
    "\n",
    "  Args:\n",
    "    logits (`2-rank Tensor`): logits\n",
    "    is_real (`bool`): boolean, Treu means `-` sign, False means `+` sign.\n",
    "\n",
    "  Returns:\n",
    "    loss (`0-rank Tensor`): the WGAN loss value.\n",
    "  \"\"\"\n",
    "  loss = tf.reduce_mean(logits)\n",
    "  if is_real:\n",
    "    loss = -loss\n",
    "\n",
    "  return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_logits, fake_logits):\n",
    "  # losses of real with label \"1\"\n",
    "  real_loss = WGANLoss(logits=real_logits, is_real=True)\n",
    "  # losses of fake with label \"0\"\n",
    "  fake_loss = WGANLoss(logits=fake_logits, is_real=False)\n",
    "  \n",
    "  return real_loss + fake_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_logits):\n",
    "  # losses of Generator with label \"1\" that used to fool the Discriminator\n",
    "  return WGANLoss(logits=fake_logits, is_real=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_optimizer = tf.keras.optimizers.RMSprop(learning_rate_D)\n",
    "generator_optimizer = tf.keras.optimizers.RMSprop(learning_rate_G)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping the random vector constant for generation (prediction) so\n",
    "# it will be easier to see the improvement of the gan.\n",
    "# To visualize progress in the animated GIF\n",
    "const_random_vector_for_saving = tf.random.uniform([num_examples_to_generate, 1, 1, noise_dim],\n",
    "                                                   minval=-1.0, maxval=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training one step function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def discriminator_train_step(images):\n",
    "  # generating noise from a uniform distribution\n",
    "  noise = tf.random.uniform([batch_size, 1, 1, noise_dim], minval=-1.0, maxval=1.0)\n",
    "\n",
    "  with tf.GradientTape() as disc_tape:\n",
    "    generated_images = generator(noise, training=True)\n",
    "\n",
    "    real_logits = discriminator(images, training=True)\n",
    "    fake_logits = discriminator(generated_images, training=True)\n",
    "\n",
    "    gen_loss = generator_loss(fake_logits)\n",
    "    disc_loss = discriminator_loss(real_logits, fake_logits)    \n",
    "\n",
    "  gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "  discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "  \n",
    "  # clip the weights for discriminator to implement 1-Lipshitz function\n",
    "  #for var in discriminator.trainable_variables:\n",
    "  #  var.assign(tf.clip_by_value(var, -0.01, 0.01))\n",
    "    \n",
    "  return gen_loss, disc_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def generator_train_step():\n",
    "  # generating noise from a uniform distribution\n",
    "  noise = tf.random.uniform([batch_size, 1, 1, noise_dim], minval=-1.0, maxval=1.0)\n",
    "\n",
    "  with tf.GradientTape() as gen_tape:\n",
    "    generated_images = generator(noise, training=True)\n",
    "\n",
    "    fake_logits = discriminator(generated_images, training=True)\n",
    "    gen_loss = generator_loss(fake_logits)\n",
    "\n",
    "  gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "  generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train full steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 20.23 global_step: 15800 Wasserstein distance: 0.245 loss_G: -6.12 (14729.78 examples/sec; 0.004 sec/batch)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x216 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Start Training.')\n",
    "num_batches_per_epoch = int(N / batch_size)\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "num_learning_critic = 0\n",
    "\n",
    "for epoch in range(1000000):\n",
    "\n",
    "  for step, images in enumerate(train_dataset):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if num_learning_critic < k:\n",
    "      gen_loss, disc_loss = discriminator_train_step(images)\n",
    "      num_learning_critic += 1\n",
    "      global_step.assign_add(1)\n",
    "    else:\n",
    "      generator_train_step()\n",
    "      num_learning_critic = 0\n",
    "    \n",
    "    if global_step.numpy() % print_steps == 0:\n",
    "      epochs = epoch + step / float(num_batches_per_epoch)\n",
    "      duration = max(time.time() - start_time, 1e-5)\n",
    "      examples_per_sec = batch_size / float(duration)\n",
    "      display.clear_output(wait=True)\n",
    "      print(\"Epochs: {:.2f} global_step: {} Wasserstein distance: {:.3g} loss_G: {:.3g} ({:.2f} examples/sec; {:.3f} sec/batch)\".format(\n",
    "                epochs, global_step.numpy(), -disc_loss, gen_loss, examples_per_sec, duration))\n",
    "      random_vector_for_sampling = tf.random.uniform([num_examples_to_generate, 1, 1, noise_dim],\n",
    "                                                     minval=-1.0, maxval=1.0)\n",
    "      sample_images = generator(random_vector_for_sampling, training=False)\n",
    "      plt.figure(figsize=[18, 3])\n",
    "      for j in range(10):\n",
    "          plt.subplot(1, 10, j+1)\n",
    "          plt.imshow(sample_images[j, :, :, 0], cmap='binary')\n",
    "          plt.xticks([])\n",
    "          plt.yticks([])\n",
    "      plt.show()     \n",
    "            \n",
    "print('Training Done.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
